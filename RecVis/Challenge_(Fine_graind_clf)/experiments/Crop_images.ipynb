{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crop_images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw-QcKGoFbV_"
      },
      "source": [
        "import torchvision\n",
        "import numpy\n",
        "import torch\n",
        "import argparse\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN_6rropvnSv"
      },
      "source": [
        "coco_names = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Jnoj-KwEaJ"
      },
      "source": [
        "# this will help us create a different color for each class\n",
        "COLORS = np.random.uniform(0, 255, size=(len(coco_names), 3))\n",
        "\n",
        "# define the torchvision image transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def predict(image, model, device, detection_threshold):\n",
        "    # transform the image to tensor\n",
        "    image = transform(image).to(device)\n",
        "    image = image.unsqueeze(0) # add a batch dimension\n",
        "    outputs = model(image) # get the predictions on the image\n",
        "    # print the results individually\n",
        "    # print(f\"BOXES: {outputs[0]['boxes']}\")\n",
        "    # print(f\"LABELS: {outputs[0]['labels']}\")\n",
        "    # print(f\"SCORES: {outputs[0]['scores']}\")\n",
        "    # get all the predicited class names\n",
        "    pred_classes = [coco_names[i] for i in outputs[0]['labels'].cpu().numpy()]\n",
        "    # get score for all the predicted objects\n",
        "    pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
        "    # get all the predicted bounding boxes\n",
        "    pred_bboxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
        "    # get boxes above the threshold score\n",
        "    boxes = pred_bboxes[pred_scores >= detection_threshold].astype(np.int32)\n",
        "    return boxes, pred_classes, outputs[0]['labels']\n",
        "\n",
        "def draw_boxes(boxes, classes, labels, image):\n",
        "    # read the image with OpenCV\n",
        "    image = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2RGB)\n",
        "    for i, box in enumerate(boxes):\n",
        "        color = COLORS[labels[i]]\n",
        "        cv2.rectangle(\n",
        "            image,\n",
        "            (int(box[0]), int(box[1])),\n",
        "            (int(box[2]), int(box[3])),\n",
        "            color, 2\n",
        "        )\n",
        "        cv2.putText(image, classes[i], (int(box[0]), int(box[1]-5)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, \n",
        "                    lineType=cv2.LINE_AA)\n",
        "    return image"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs4b7CervdtG"
      },
      "source": [
        "# construct the argument parser\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-i', '--input', help='path to input image/video')\n",
        "parser.add_argument('-m', '--min-size', dest='min_size', default=800, \n",
        "                    help='minimum input size for the FasterRCNN network')\n",
        "args = {'min_size':800,'input':'/content/recvis20_a3/bird_dataset/test_images/mistery_category/002f61512a368e4c1434eedacf609957.jpg'}\n",
        "\n",
        "# download or load the model from disk\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, \n",
        "                                                    min_size=args['min_size'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc-d4bIWxS3S"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "image = Image.open(args['input'])\n",
        "model.eval().to(device)\n",
        "boxes, classes, labels = predict(image, model, device, 0.8)\n",
        "image = draw_boxes(boxes, classes, labels, image)\n",
        "cv2_imshow(image)\n",
        "save_name = f\"{args['input'].split('/')[-1].split('.')[0]}_{args['min_size']}\"\n",
        "cv2.imwrite(f\"outputs/{save_name}.jpg\", image)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRSMcB1h82xo"
      },
      "source": [
        "def crop(img_path,new_path,threshold=0.8):\n",
        "  image = Image.open(img_path)\n",
        "  image = transform(image).to(device)\n",
        "  image = image.unsqueeze(0) # add a batch dimension\n",
        "\n",
        "  outputs = model(image) # get the predictions on the image\n",
        "  pred_scores = outputs[0]['scores'].detach().cpu().numpy()\n",
        "  pred_boxes = outputs[0]['boxes'].detach().cpu().numpy()\n",
        "  labels      = outputs[0]['labels'].detach().cpu().numpy()\n",
        "  # get boxes who have a bird tag\n",
        "  bird_hits = pred_boxes[labels==16].astype(np.int32)\n",
        "\n",
        "  no_match= False\n",
        "\n",
        "\n",
        "  if bird_hits.size !=0:\n",
        "    bird_scores = pred_scores[labels==16]\n",
        "    box = bird_hits[bird_scores == np.max(bird_scores)][0]\n",
        "\n",
        "  if bird_hits.size ==0 :\n",
        "    \n",
        "    print(\"Found no matches in\",img_path)\n",
        "    no_match = True\n",
        "    max_hit = pred_boxes[pred_scores == np.max(pred_scores)]\n",
        "    box  = max_hit[0]\n",
        "\n",
        "  \n",
        "  image = transforms.ToPILImage()(image.squeeze())\n",
        "  image=image.crop(box)\n",
        "  image.save(new_path , \"JPEG\")\n",
        "\n",
        "  return no_match\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzVmmJjQGu7B"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "old_path = '/content/recvis20_a3/bird_dataset/val_images'\n",
        "new_path = '/content/bird_dataset_c/val_cropped'\n",
        "\n",
        "def crop_dataset(old_path=old_path,new_path=new_path):\n",
        "\n",
        "\n",
        "  !rm -r  $new_path\n",
        "  os.mkdir(new_path)\n",
        "  classes = os.listdir(old_path)\n",
        "\n",
        "  no_match_cnt = 0\n",
        "  for class_ in classes :\n",
        "    \n",
        "    print(\"Cropping class\",class_)\n",
        "    \n",
        "    old_class_path = os.path.join(old_path,class_)\n",
        "    new_class_path = os.path.join(new_path,class_)\n",
        "    os.mkdir(new_class_path)  \n",
        "\n",
        "    for img in os.listdir(old_class_path):\n",
        "\n",
        "      old_img_path = os.path.join(old_class_path,img)\n",
        "      new_img_path = os.path.join(new_class_path,img)\n",
        "      no_match_cnt += crop(old_img_path,new_img_path)\n",
        "    \n",
        "  print(f'Found {no_match_cnt} images with no birds')\n",
        "\n",
        "\n",
        "crop_dataset()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}